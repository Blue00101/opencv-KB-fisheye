{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Xin Zan 489072703@qq.com\n",
    "Date: 2025-3-25 14:26:29\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zanxin/zanxin/calib/290_230816/frame_000001.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000002.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000003.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000004.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000005.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000006.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000007.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000008.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000009.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000010.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000011.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000012.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000013.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000014.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000015.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000016.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000017.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000018.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000019.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000020.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000021.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000022.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000023.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000024.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000025.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000026.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000027.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000028.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000029.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000030.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000031.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000032.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000033.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000034.jpg\n",
      "/home/zanxin/zanxin/calib/290_230816/frame_000035.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "assert cv2.__version__[0] == '3', 'The fisheye module requires opencv version >= 3.0.0'\n",
    "import numpy as np\n",
    "import os\n",
    "from path import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_dir = Path(f'/home/zanxin/zanxin/calib/290_230816')\n",
    "images = sorted(img_dir.glob('*.jpg'))\n",
    "for img in images:\n",
    "    print(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKERBOARD = (15, 10) # \n",
    "# square_size = 10 # c3vd\n",
    "\n",
    "CHECKERBOARD = (8, 8) # 9x9 的棋盘格， pattern_size应该为 8x8\n",
    "square_size = 6 # 6 看棋盘格的尺寸，我的为 9*9*6mm\n",
    "\n",
    "subpix_criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "calibration_flags = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC+cv2.fisheye.CALIB_CHECK_COND+cv2.fisheye.CALIB_FIX_SKEW\n",
    "objp = np.zeros((1, CHECKERBOARD[0]*CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2) * square_size\n",
    "\n",
    "_img_shape = None\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    if _img_shape == None:\n",
    "        _img_shape = img.shape[:2]\n",
    "    else:\n",
    "        assert _img_shape == img.shape[:2], \"All images must share the same size.\"\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    # ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH+cv2.CALIB_CB_FAST_CHECK+cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH+cv2.CALIB_CB_FAST_CHECK+cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        cv2.cornerSubPix(gray,corners,(3,3),(-1,-1),subpix_criteria)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "    #可视化提取的角点\n",
    "        cv2.drawChessboardCorners(img, CHECKERBOARD, corners, ret)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f'{fname} has not detected corners')\n",
    "        \n",
    "N_OK = len(objpoints)\n",
    "K = np.zeros((3, 3))\n",
    "D = np.zeros((4, 1))\n",
    "rvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_OK)]\n",
    "tvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_OK)]\n",
    "\n",
    "rms, _, _, _, _ = \\\n",
    "    cv2.fisheye.calibrate(\n",
    "        objpoints,\n",
    "        imgpoints,\n",
    "        gray.shape[::-1],\n",
    "        K,\n",
    "        D,\n",
    "        rvecs,\n",
    "        tvecs,\n",
    "        calibration_flags,\n",
    "        (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6)\n",
    "    )\n",
    "print(\"Found \" + str(N_OK) + \" valid images for calibration\")\n",
    "print(\"DIM=\" + str(_img_shape[::-1]))\n",
    "print(\"K=np.array(\" + str(K.tolist()) + \")\")\n",
    "print(\"D=np.array(\" + str(D.tolist()) + \")\")\n",
    "print(f'rms is: {rms}')\n",
    "\n",
    "# # 计算每张图的重投影误差\n",
    "# for i in range(N_OK):\n",
    "#     projected_points, _ = cv2.fisheye.projectPoints(objpoints[i].reshape(-1,1,3), rvecs[i], tvecs[i], K, D)\n",
    "    \n",
    "#     error = imgpoints[i] - projected_points\n",
    "#     rms_error = np.sqrt(np.mean(error**2))\n",
    "#     print(f'Image {images[i]} RMS error: {rms_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from path import Path\n",
    "import cv2\n",
    "\n",
    "# # 260 240904\n",
    "# DIM=(1162, 1007)\n",
    "# K=np.array([[715.6165462654658, 0.0, 579.6111529424028], [0.0, 716.3003536681483, 512.0439619738358], [0.0, 0.0, 1.0]])\n",
    "# D=np.array([[-0.1136918020178839], [-0.00270267936430549], [-0.0848114182515754], [0.13132640795529404]])\n",
    "# fx, fy = K[0, 0], K[1, 1]\n",
    "# cx, cy = K[0, 2], K[1, 2]\n",
    "# # rms is: 0.641217717542028\n",
    "\n",
    "# # 290 230816\n",
    "# DIM=(1162, 1007)\n",
    "# K=np.array([[717.323474888361, 0.0, 576.588439310983], [0.0, 717.1064552631971, 510.42880651166683], [0.0, 0.0, 1.0]])\n",
    "# D=np.array([[-0.10448185927561918], [-0.09679781611180353], [0.26074952843829363], [-0.2652240025401324]])\n",
    "# # rms is: 0.5726074686684097\n",
    "\n",
    "# c3vd\n",
    "DIM=(1350, 1080)\n",
    "K=np.array([[767.3980383329763, 0.0, 679.0545976908313], [0.0, 767.5170358974989, 543.645636252986], [0.0, 0.0, 1.0]])\n",
    "D=np.array([[-0.1887138199236522], [-0.00379847687735559], [0.030352421612693584], [-0.012679529136190738]])\n",
    "# rms is: 0.6742308502882097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img_path, output_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    # cv2.imwrite(f'{output_path}/{img_path.stem:04d}+.png', undistorted_img)\n",
    "    cv2.imwrite(output_path/img_path.stem+'.png', undistorted_img)\n",
    "\n",
    "\n",
    "##### 处理C3VD数据集的cecum_t1_a文件夹的rgb文件\n",
    "# def undistort_t1_a_color(img_path, output_path):\n",
    "#     img = cv2.imread(img_path)\n",
    "#     h, w = img.shape[:2]\n",
    "\n",
    "#     map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "#     undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "#     cv2.imwrite(f'{output_path}/{int(img_path.stem[:-6]):04d}_color.png', undistorted_img)\n",
    "#     # cv2.imwrite(output_path/img_path.stem+'.png', undistorted_img)\n",
    "\n",
    "###### 处理C3VD数据集的深度和光流\n",
    "def undistort_depth(img_path, output_path):\n",
    "    img = cv2.imread(img_path, -1) # uint16 65535, uint8 255\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    undistorted_img = 100.0 * undistorted_img.astype(np.float32) / 65535.0\n",
    "    # cv2.imwrite(output_path/img_path.stem+'.png', undistorted_img)\n",
    "    (output_path/'gt_npy').makedirs_p()\n",
    "    np.save(output_path/'gt_npy'/img_path.stem+'.npy', undistorted_img)\n",
    "    # return undistorted_img\n",
    "\n",
    "def undistort_flow(img_path, output_path):\n",
    "    img = cv2.imread(img_path, -1) # uint16 65535, uint8 255\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    undistorted_img = 40.0 * ((undistorted_img.astype(np.float32) - 32768.0) / 65535.0)\n",
    "    # cv2.imwrite(output_path/img_path.stem+'.png', undistorted_img)\n",
    "    (output_path/'gt_npy_flow').makedirs_p()\n",
    "    np.save(output_path/'gt_npy_flow'/img_path.stem+'.npy', undistorted_img)\n",
    "    # return undistorted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scene 0020620186:: 100%|██████████| 54/54 [00:06<00:00,  8.57it/s]\n",
      "Processing scene 0032486908:: 100%|██████████| 19/19 [00:02<00:00,  8.11it/s]\n",
      "Processing scene 0039693507:: 100%|██████████| 45/45 [00:05<00:00,  8.49it/s]\n",
      "Processing scene 0021251559:: 100%|██████████| 168/168 [00:20<00:00,  8.27it/s]\n",
      "Processing scene 0032796274:: 100%|██████████| 41/41 [00:04<00:00,  8.21it/s]\n",
      "Processing scene 0039364429:: 100%|██████████| 29/29 [00:03<00:00,  8.35it/s]\n",
      "Processing scene 0035958584:: 100%|██████████| 112/112 [00:12<00:00,  8.97it/s]\n",
      "Processing scene 0020422179:: 100%|██████████| 72/72 [00:08<00:00,  8.87it/s]\n",
      "Processing scene 0033407811:: 100%|██████████| 21/21 [00:02<00:00,  8.66it/s]\n",
      "Processing scene 0034996321:: 100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n"
     ]
    }
   ],
   "source": [
    "distortion_img_path = Path(f'/home/zanxin/zanxin/datasets/241211/crop')\n",
    "output_path = Path(f'/home/zanxin/zanxin/datasets/241211/undist_fisheye')\n",
    "\n",
    "scenes = distortion_img_path.listdir()\n",
    "for scene in scenes:\n",
    "    output_dir = Path(output_path/scene.stem)\n",
    "    output_dir.makedirs_p()\n",
    "    \n",
    "    images = sorted(scene.glob('*.png'))\n",
    "    for img in tqdm(images, desc=f'Processing scene {scene.stem}:'):\n",
    "        undistort(img, output_dir)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calib_frames\n",
      "cecum_t1_a\n",
      "cecum_t1_b\n",
      "cecum_t2_a\n",
      "cecum_t2_b\n",
      "cecum_t2_c\n",
      "cecum_t3_a\n",
      "cecum_t4_a\n",
      "cecum_t4_b\n",
      "desc_t4_a\n",
      "sigmoid_t1_a\n",
      "sigmoid_t2_a\n",
      "sigmoid_t3_a\n",
      "sigmoid_t3_b\n",
      "trans_t1_a\n",
      "trans_t1_b\n",
      "trans_t2_a\n",
      "trans_t2_b\n",
      "trans_t2_c\n",
      "trans_t3_a\n",
      "trans_t3_b\n",
      "trans_t4_a\n",
      "trans_t4_b\n"
     ]
    }
   ],
   "source": [
    "# cfhq190l_10x10mm_checkerboard_images\n",
    "# c3vd_path = Path(f'/mnt/c3vd_origin')\n",
    "# output_path = Path(f'/home/zanxin/zanxin/datasets/c3vd_fisheye_opencv')\n",
    "\n",
    "c3vd_path = Path(f'/root/autodl-tmp/c3vd-dataset')\n",
    "output_path = Path(f'/root/autodl-fs/c3vd-KB-fisheye')\n",
    "\n",
    "scenes = c3vd_path.listdir()\n",
    "scenes = sorted([f for f in scenes if f.stem != 'cfhq190l_10x10mm_checkerboard_images' and f.stem != '.Trash-1000' and f.stem != 'undist_fisheye' and f.stem != 'unzip_all'])\n",
    "\n",
    "\n",
    "for scene in scenes:\n",
    "    print(scene.stem)\n",
    "    \n",
    "    output_dir = Path(output_path/scene.stem)\n",
    "    output_dir.makedirs_p()\n",
    "    \n",
    "    rgb = sorted(scene.glob('*color.png'))\n",
    "    depth = sorted(scene.glob('*depth.tiff'))\n",
    "    flow = sorted(scene.glob('*flow.tiff'))\n",
    "\n",
    "    # for img in tqdm(rgb, desc=f'Processing scene {scene.stem} rgb:'):\n",
    "    #     # undistort(img, output_dir)\n",
    "    #     undistort_t1_a_color(img, output_dir)\n",
    "    #     # print(img.stem[:-6])\n",
    "    \n",
    "    for img in tqdm(depth, desc=f'depth:'):\n",
    "        undistort_depth(img, output_dir)\n",
    "        undistort(img, output_dir)\n",
    "\n",
    "    for img in tqdm(flow, desc=f'flow:'):\n",
    "        undistort_flow(img, output_dir)\n",
    "        undistort(img, output_dir)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zx-fisheye-py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
